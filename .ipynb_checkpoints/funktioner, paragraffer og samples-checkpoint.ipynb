{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split as tts\n",
    "import statsmodels.formula.api as smf\n",
    "import nltk\n",
    "sns.set\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('13300.csv') ## Hent DataFrame\n",
    "\n",
    "def text_to_paragraphs(tekster):\n",
    "    \"\"\"\n",
    "    Funktionens formål er at dele alle tekster i vores dataframe i deres paragraffer, og derefter folde dataframen ud,\n",
    "    således at alle paragraffer har en row for sig selv.\n",
    "    Input: en list med strings, hvor vores strings er lig med vores tekster.\n",
    "    Output: en dataframe.\n",
    "    \"\"\"\n",
    "    paragraffs = [] # holdinglist til alle paragraffer (resultatet bliver en liste i en liste)\n",
    "    ### looper over alle tekster.\n",
    "    for i in tekster:\n",
    "        try:\n",
    "            val = nltk.tokenize.line_tokenize(i) #tokenizer på linjeskift(paragraffer) \n",
    "            paragraffs.append(val) \n",
    "        except (AttributeError) as err: ## printer Error, som value, når der ikke forekommer en tekst\n",
    "            val = 'Error'               ## Vi printer Error, som value, for at beholde det rette index\n",
    "            paragraffs.append(val)      ##\n",
    "\n",
    "    df1['paragraffs'] = paragraffs # paragrafferne tilføjes til DF, som en liste med strings.\n",
    "    # der laves en ny dataframe, hvor listerne paragraffer foldes ud.\n",
    "    df_para = df1.apply(lambda x: pd.Series(x['paragraffs']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "    df_para.name = 'paragraffer'\n",
    "    # dataframes merges til en endelig datafram, hvor alle paragraffer er foldet ud. \n",
    "    df1_p = df1.drop('paragraffs', axis=1).join(df_para)\n",
    "    df1_p = df1_p.drop('Unnamed: 0', axis=1)\n",
    "    # konverter alt text til lower case\n",
    "    df1_p = df1_p.apply(lambda x: x.astype(str).str.lower())\n",
    "    emner = ['international politik','økonomi & velfærd','ret & politi','familie & børn','uddannelse','kultur & religion','køn & ligestilling','medier, kommunikation & it','miljø & klima','flygtninge & intengrationspolitik','andet','ignore']\n",
    "    for i in emner:\n",
    "        df1_p[i] = pd.Series()\n",
    "    return df1_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_p = text_to_paragraphs(df1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample(sample_size):\n",
    "    df1_p_sample = df1_p.sample(n=sample_size, random_state=1)\n",
    "    \"\"\"\n",
    "    Funktionens formål er at lave et tilfældigt udtræk af paragraffer fra vores dataframe, og fordele dem tilfældigt i\n",
    "    4 samples. dernæst lægges \n",
    "    Input: en list med strings, hvor vores strings er lig med vores tekster.\n",
    "    Output: en dataframe.\n",
    "    \"\"\"\n",
    "    # generate 2000 random rows for sampling\n",
    "    j = int(sample_size/4)\n",
    "    # split the samples into 4\n",
    "    part1_sample1 = df1_p_sample[0:j-1]\n",
    "    part1_sample2 = df1_p_sample[j:j*2-1]\n",
    "    part1_sample3 = df1_p_sample[j*2:j*3-1]\n",
    "    part1_sample4 = df1_p_sample[j*3:sample_size-1]\n",
    "     # concatenate all combinations of 3 parts of the sample\n",
    "    f1 = pd.concat([pd.concat([part1_sample2, part1_sample3]), part1_sample4])\n",
    "    f2 = pd.concat([pd.concat([part1_sample1, part1_sample3]), part1_sample4])\n",
    "    f3 = pd.concat([pd.concat([part1_sample1, part1_sample2]), part1_sample4])\n",
    "    f4 = pd.concat([pd.concat([part1_sample1, part1_sample2]), part1_sample3])\n",
    "    # generate a random sample af the groups of 3\n",
    "    part2_sample1 = f1.sample(frac=0.0333, random_state=2)\n",
    "    part2_sample2 = f2.sample(frac=0.0333, random_state=3)\n",
    "    part2_sample3 = f3.sample(frac=0.0333, random_state=4)\n",
    "    part2_sample4 = f4.sample(frac=0.0333, random_state=5)\n",
    "    # concat every part of the sample, with the randomly generated sample from the group, that it was not a part of.\n",
    "    sample1 = pd.concat([part1_sample1, part2_sample1])\n",
    "    sample2 = pd.concat([part1_sample2, part2_sample2])\n",
    "    sample3 = pd.concat([part1_sample3, part2_sample3])\n",
    "    sample4 = pd.concat([part1_sample4, part2_sample4])\n",
    "    return sample1, sample2, sample3, sample4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = random_sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import ExcelWriter\n",
    "# gem samples som excel filer\n",
    "writer1 = ExcelWriter('sample1.xlsx')\n",
    "samples[0].to_excel(writer1,'Sheet1')\n",
    "writer1.save()\n",
    "\n",
    "writer2 = ExcelWriter('sample2.xlsx')\n",
    "samples[1].to_excel(writer2,'Sheet1')\n",
    "writer2.save()\n",
    "\n",
    "writer3 = ExcelWriter('sample3.xlsx')\n",
    "samples[2].to_excel(writer3,'Sheet1')\n",
    "writer3.save()\n",
    "\n",
    "writer4 = ExcelWriter('sample4.xlsx')\n",
    "samples[3].to_excel(writer4,'Sheet1')\n",
    "writer4.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
